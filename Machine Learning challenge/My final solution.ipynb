{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identification\n",
    "yourNameSurname='Niccolò Morabito'\n",
    "yourMatricolaNumber='1808746'\n",
    "yourStudentEMAIL='morabito.1808746@studenti.uniroma1.it'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning 2020/2021 - Challenge \n",
    "\n",
    "#### 1. Mandatory Rules\n",
    "#### 2. The Dataset\n",
    "- #### 2.1 Load the dataset\n",
    "- #### 2.2 Dataset Analysis\n",
    "\n",
    "#### 3. Classification\n",
    "- #### 3.1 Preprocessing\n",
    "- #### 3.2 Model Selection\n",
    "- #### 3.3 Evaluation\n",
    "\n",
    "#### 4. Summary\n",
    "\n",
    "\n",
    "<hr>\n",
    "\n",
    "## 1. Mandatory Rules (read carefully):\n",
    "- This year the results of the challenges will count 8/30 of your final score.\n",
    "- Only one submission is allowed. We will not consider multiple submissions.\n",
    "- Please remember your solution must be <b>\"YOUR SOLUTION\"</b>, hence you are requested to deliver your individual answers/arguments/opinions/critics.\n",
    "- Mail your solution (a <b>jupyter notebook</b>) only to stefano.faralli@unitelmasapienza.it <b>10 days before the date of a written exam (NO EXCEPTIONS)</b> if you miss to deliver your solution you must wait the next (if any) available deadline. \n",
    "- The subject of your email must be: \"[Challenge_solution] NAME - SURNAME - MATRICOLA\".\n",
    "- Double check the subject of your email and the attachments.\n",
    "- In case you want to compress the attachment, <b>USE ONLY STANDARD ZIP compression</b> (NO RAR,7Z etc..).\n",
    "- <b>Please sumbit ONLY the notebook with SAVED OUTPUTS!</b>.\n",
    "- Your solution might be considered as the \"copy\" of others solutions, in that specific case the resulting score for all involved students will be 0/8.\n",
    "- Then read carefully all the part of the jupyter notebook and fill all fields.\n",
    "- <b>solutions (and correspondig points) are evaluated mainly on your thoughts/comments/opinions</b>.  \n",
    "- If you have questions <b>Don't write \"personal\" emails</b> to Stefano Faralli, instead <b>use our google group</b>.\n",
    "- A solution having a summary discussion with less than 500 words is evaluated with 0 points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## 2. The Dataset (up to 1/8 points)\n",
    "<img width='400' src='videogames.jpg'/>\n",
    "\n",
    "- The topic of the challenge is \"Video games\";\n",
    "- The dataset consists of one single csv file (\"video_games.csv\");\n",
    "- The full description of the dataset is available at: <a href='https://corgis-edu.github.io//corgis/csv/video_games/'>github project page</a>;\n",
    "\n",
    "[1] Cox, Joe. “What makes a blockbuster video game? An empirical analysis of US sales data.” Managerial and Decision Economics 35.3 (2014): 189-198\n",
    "\n",
    "## 2.1 Load the Dataset (up to 0.2/8 points)\n",
    "In the following two cells: a code cell and, a markdown cell, where: \n",
    "- you write the code to create a pandas DataFrame by loading the \"video_games.csv\" file.  \n",
    "- you describe the problems and the solution for loading the same csv file to a numpy datastructure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title                            category\n",
       "Features.Handheld?                   bool\n",
       "Features.Max Players                int64\n",
       "Features.Multiplatform?              bool\n",
       "Features.Online?                     bool\n",
       "Metadata.Genres                  category\n",
       "Metadata.Licensed?                   bool\n",
       "Metadata.Publishers              category\n",
       "Metadata.Sequel?                     bool\n",
       "Metrics.Review Score                int64\n",
       "Metrics.Sales                     float64\n",
       "Metrics.Used Price                float64\n",
       "Release.Console                  category\n",
       "Release.Rating                   category\n",
       "Release.Re-release?                  bool\n",
       "Release.Year                        int64\n",
       "Length.All PlayStyles.Average     float64\n",
       "Length.All PlayStyles.Leisure     float64\n",
       "Length.All PlayStyles.Median      float64\n",
       "Length.All PlayStyles.Polled        int64\n",
       "Length.All PlayStyles.Rushed      float64\n",
       "Length.Completionists.Average     float64\n",
       "Length.Completionists.Leisure     float64\n",
       "Length.Completionists.Median      float64\n",
       "Length.Completionists.Polled        int64\n",
       "Length.Completionists.Rushed      float64\n",
       "Length.Main + Extras.Average      float64\n",
       "Length.Main + Extras.Leisure      float64\n",
       "Length.Main + Extras.Median       float64\n",
       "Length.Main + Extras.Polled         int64\n",
       "Length.Main + Extras.Rushed       float64\n",
       "Length.Main Story.Average         float64\n",
       "Length.Main Story.Leisure         float64\n",
       "Length.Main Story.Median          float64\n",
       "Length.Main Story.Polled            int64\n",
       "Length.Main Story.Rushed          float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read dataset\n",
    "df = pd.read_csv('video_games.csv', header=0)\n",
    "\n",
    "# type conversion for some string columns\n",
    "df['Title'] = df['Title'].astype('category')\n",
    "df['Metadata.Genres'] = df['Metadata.Genres'].astype('category')\n",
    "df['Metadata.Publishers'] = df['Metadata.Publishers'].astype('category')\n",
    "df['Release.Console'] = df['Release.Console'].astype('category')\n",
    "df['Release.Rating'] = df['Release.Rating'].astype('category')\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset is loaded creating a DataFrame - categorical features types are converted into the right type just for clarity. \n",
    "\n",
    "Loading the csv file with pandas DataFrame is quite easy because you just have to specify the csv filename as a parameter of `read_csv()` method. `header` parameter is 0 by default and this allows to infer the column names from the header of the file.\n",
    "\n",
    "In order to load a dataset from csv to a numpy data structure you can use `genfromtxt()`, which has similar behaviour. The first difference is the separator, which by default is different between the two methods. However, there are other differences that constitute some problems:\n",
    "\n",
    "- `genfromtxt()` will give an error if the number of columns is unequal in the different rows. Possible solution: to pass the parameter `usecols=np.arange(0,C)`, where `C` = #columns in the header\n",
    "\n",
    "- `genfromtxt()` can deal with data types using the parameter `dtype` which represents the data type of the resulting array and if it is `None` the dtypes will be individually determined by the contents of each column. However, if the values of the csv are included between double quotes (as in this case), the types are not inferred and all the values are treated as a string with double quotes inside. Instead, `read_csv()` automatically recognize types, distinguishing between object, boolean and numbers (`int` or `float`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Dataset Analysis (up to 0.8/8 points)\n",
    "In the following code cell (feel free to create new cells), remember to comment your code snippets:\n",
    "\n",
    "1) Print the total number of samples;\n",
    "\n",
    "2) Print a table with the first 15 samples;\n",
    "\n",
    "3) Plot the histogram distribution of \"Features.Handheld?\";\n",
    "\n",
    "4) Plot the histogram distribution of \"Features.Online?\";\n",
    "\n",
    "5) Plot the histogram distribution of \"Metadata.Publishers\";\t\n",
    "\n",
    "6) Perform feature importance analysis; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of instances is: 1212\n"
     ]
    }
   ],
   "source": [
    "# 1) printing the total number of samples\n",
    "n_samples = df.shape[0]\n",
    "print(f\"The total number of instances is: {n_samples}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pandas.DataFrame.shape`, accordingly to the documentation, returns a tuple representing the dimensionality of the DataFrame. The first element of this tuple corresponds to the number of samples, the second one to the number of columns. The videogames dataset contains 1212 instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Features.Handheld?</th>\n",
       "      <th>Features.Max Players</th>\n",
       "      <th>Features.Multiplatform?</th>\n",
       "      <th>Features.Online?</th>\n",
       "      <th>Metadata.Genres</th>\n",
       "      <th>Metadata.Licensed?</th>\n",
       "      <th>Metadata.Publishers</th>\n",
       "      <th>Metadata.Sequel?</th>\n",
       "      <th>Metrics.Review Score</th>\n",
       "      <th>Metrics.Sales</th>\n",
       "      <th>Metrics.Used Price</th>\n",
       "      <th>Release.Console</th>\n",
       "      <th>Release.Rating</th>\n",
       "      <th>Release.Re-release?</th>\n",
       "      <th>Release.Year</th>\n",
       "      <th>Length.All PlayStyles.Average</th>\n",
       "      <th>Length.All PlayStyles.Leisure</th>\n",
       "      <th>Length.All PlayStyles.Median</th>\n",
       "      <th>Length.All PlayStyles.Polled</th>\n",
       "      <th>Length.All PlayStyles.Rushed</th>\n",
       "      <th>Length.Completionists.Average</th>\n",
       "      <th>Length.Completionists.Leisure</th>\n",
       "      <th>Length.Completionists.Median</th>\n",
       "      <th>Length.Completionists.Polled</th>\n",
       "      <th>Length.Completionists.Rushed</th>\n",
       "      <th>Length.Main + Extras.Average</th>\n",
       "      <th>Length.Main + Extras.Leisure</th>\n",
       "      <th>Length.Main + Extras.Median</th>\n",
       "      <th>Length.Main + Extras.Polled</th>\n",
       "      <th>Length.Main + Extras.Rushed</th>\n",
       "      <th>Length.Main Story.Average</th>\n",
       "      <th>Length.Main Story.Leisure</th>\n",
       "      <th>Length.Main Story.Median</th>\n",
       "      <th>Length.Main Story.Polled</th>\n",
       "      <th>Length.Main Story.Rushed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Super Mario 64 DS</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Action</td>\n",
       "      <td>True</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>True</td>\n",
       "      <td>85</td>\n",
       "      <td>4.69</td>\n",
       "      <td>24.95</td>\n",
       "      <td>Nintendo DS</td>\n",
       "      <td>E</td>\n",
       "      <td>True</td>\n",
       "      <td>2004</td>\n",
       "      <td>22.716667</td>\n",
       "      <td>31.900000</td>\n",
       "      <td>24.483333</td>\n",
       "      <td>57</td>\n",
       "      <td>14.300000</td>\n",
       "      <td>29.766667</td>\n",
       "      <td>35.033333</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>20</td>\n",
       "      <td>22.016667</td>\n",
       "      <td>24.916667</td>\n",
       "      <td>29.966667</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>16</td>\n",
       "      <td>18.333333</td>\n",
       "      <td>14.333333</td>\n",
       "      <td>18.316667</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>21</td>\n",
       "      <td>9.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lumines: Puzzle Fusion</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Strategy</td>\n",
       "      <td>True</td>\n",
       "      <td>Ubisoft</td>\n",
       "      <td>True</td>\n",
       "      <td>89</td>\n",
       "      <td>0.56</td>\n",
       "      <td>14.95</td>\n",
       "      <td>Sony PSP</td>\n",
       "      <td>E</td>\n",
       "      <td>True</td>\n",
       "      <td>2004</td>\n",
       "      <td>10.100000</td>\n",
       "      <td>11.016667</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>9.516667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.750000</td>\n",
       "      <td>9.866667</td>\n",
       "      <td>9.750000</td>\n",
       "      <td>2</td>\n",
       "      <td>9.616667</td>\n",
       "      <td>10.333333</td>\n",
       "      <td>11.083333</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>9.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WarioWare Touched!</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Action,Racing / Driving,Sports</td>\n",
       "      <td>True</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>True</td>\n",
       "      <td>81</td>\n",
       "      <td>0.54</td>\n",
       "      <td>22.95</td>\n",
       "      <td>Nintendo DS</td>\n",
       "      <td>E</td>\n",
       "      <td>True</td>\n",
       "      <td>2004</td>\n",
       "      <td>4.566667</td>\n",
       "      <td>11.566667</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>57</td>\n",
       "      <td>2.266667</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>14.100000</td>\n",
       "      <td>7.250000</td>\n",
       "      <td>16</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>3.850000</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>11</td>\n",
       "      <td>2.783333</td>\n",
       "      <td>1.916667</td>\n",
       "      <td>2.933333</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>30</td>\n",
       "      <td>1.433333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hot Shots Golf: Open Tee</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Sports</td>\n",
       "      <td>True</td>\n",
       "      <td>Sony</td>\n",
       "      <td>True</td>\n",
       "      <td>81</td>\n",
       "      <td>0.49</td>\n",
       "      <td>12.95</td>\n",
       "      <td>Sony PSP</td>\n",
       "      <td>E</td>\n",
       "      <td>True</td>\n",
       "      <td>2004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spider-Man 2</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Action</td>\n",
       "      <td>True</td>\n",
       "      <td>Activision</td>\n",
       "      <td>True</td>\n",
       "      <td>61</td>\n",
       "      <td>0.45</td>\n",
       "      <td>14.95</td>\n",
       "      <td>Nintendo DS</td>\n",
       "      <td>E</td>\n",
       "      <td>True</td>\n",
       "      <td>2004</td>\n",
       "      <td>13.250000</td>\n",
       "      <td>48.383333</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>37</td>\n",
       "      <td>7.066667</td>\n",
       "      <td>72.566667</td>\n",
       "      <td>78.866667</td>\n",
       "      <td>72.566667</td>\n",
       "      <td>2</td>\n",
       "      <td>66.283333</td>\n",
       "      <td>12.766667</td>\n",
       "      <td>17.316667</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>12</td>\n",
       "      <td>10.483333</td>\n",
       "      <td>8.350000</td>\n",
       "      <td>11.083333</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>23</td>\n",
       "      <td>5.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Urbz: Sims in the City</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Simulation</td>\n",
       "      <td>True</td>\n",
       "      <td>EA</td>\n",
       "      <td>True</td>\n",
       "      <td>67</td>\n",
       "      <td>0.41</td>\n",
       "      <td>12.95</td>\n",
       "      <td>Nintendo DS</td>\n",
       "      <td>M</td>\n",
       "      <td>True</td>\n",
       "      <td>2004</td>\n",
       "      <td>21.933333</td>\n",
       "      <td>25.500000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>16.733333</td>\n",
       "      <td>30.033333</td>\n",
       "      <td>30.033333</td>\n",
       "      <td>30.033333</td>\n",
       "      <td>2</td>\n",
       "      <td>30.033333</td>\n",
       "      <td>20.833333</td>\n",
       "      <td>25.200000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>16.450000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>15.750000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>2</td>\n",
       "      <td>15.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ridge Racer</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Racing / Driving</td>\n",
       "      <td>True</td>\n",
       "      <td>Namco</td>\n",
       "      <td>True</td>\n",
       "      <td>88</td>\n",
       "      <td>0.36</td>\n",
       "      <td>19.95</td>\n",
       "      <td>Sony PSP</td>\n",
       "      <td>E</td>\n",
       "      <td>True</td>\n",
       "      <td>2004</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>1.050000</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>6</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>2</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>3</td>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Metal Gear Ac!d</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Strategy</td>\n",
       "      <td>True</td>\n",
       "      <td>Konami</td>\n",
       "      <td>True</td>\n",
       "      <td>75</td>\n",
       "      <td>0.34</td>\n",
       "      <td>17.95</td>\n",
       "      <td>Sony PSP</td>\n",
       "      <td>E</td>\n",
       "      <td>True</td>\n",
       "      <td>2004</td>\n",
       "      <td>25.383333</td>\n",
       "      <td>51.650000</td>\n",
       "      <td>21.266667</td>\n",
       "      <td>18</td>\n",
       "      <td>19.166667</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>24.833333</td>\n",
       "      <td>27.483333</td>\n",
       "      <td>25.100000</td>\n",
       "      <td>6</td>\n",
       "      <td>21.916667</td>\n",
       "      <td>20.700000</td>\n",
       "      <td>23.600000</td>\n",
       "      <td>20.783333</td>\n",
       "      <td>11</td>\n",
       "      <td>17.883333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Madden NFL 2005</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Sports</td>\n",
       "      <td>True</td>\n",
       "      <td>EA</td>\n",
       "      <td>True</td>\n",
       "      <td>68</td>\n",
       "      <td>0.25</td>\n",
       "      <td>8.95</td>\n",
       "      <td>Nintendo DS</td>\n",
       "      <td>T</td>\n",
       "      <td>True</td>\n",
       "      <td>2004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Pokmon Dash</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Racing / Driving</td>\n",
       "      <td>True</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>True</td>\n",
       "      <td>46</td>\n",
       "      <td>0.22</td>\n",
       "      <td>24.95</td>\n",
       "      <td>Nintendo DS</td>\n",
       "      <td>T</td>\n",
       "      <td>True</td>\n",
       "      <td>2004</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>7.250000</td>\n",
       "      <td>1.183333</td>\n",
       "      <td>4</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.116667</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>1.083333</td>\n",
       "      <td>3</td>\n",
       "      <td>1.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Dynasty Warriors</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Action,Adventure,Role-Playing (RPG)</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>62</td>\n",
       "      <td>0.20</td>\n",
       "      <td>14.95</td>\n",
       "      <td>Sony PSP</td>\n",
       "      <td>E</td>\n",
       "      <td>True</td>\n",
       "      <td>2004</td>\n",
       "      <td>8.883333</td>\n",
       "      <td>18.050000</td>\n",
       "      <td>2.083333</td>\n",
       "      <td>4</td>\n",
       "      <td>3.116667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.883333</td>\n",
       "      <td>18.050000</td>\n",
       "      <td>2.083333</td>\n",
       "      <td>4</td>\n",
       "      <td>3.116667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Feel the Magic XY/XX</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Action,Adventure,Racing / Driving,Sports</td>\n",
       "      <td>True</td>\n",
       "      <td>Sega</td>\n",
       "      <td>True</td>\n",
       "      <td>75</td>\n",
       "      <td>0.16</td>\n",
       "      <td>8.95</td>\n",
       "      <td>Nintendo DS</td>\n",
       "      <td>T</td>\n",
       "      <td>True</td>\n",
       "      <td>2004</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>2.316667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>3.150000</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>2</td>\n",
       "      <td>3.050000</td>\n",
       "      <td>2.850000</td>\n",
       "      <td>3.783333</td>\n",
       "      <td>2.983333</td>\n",
       "      <td>7</td>\n",
       "      <td>2.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Ridge Racer DS</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Racing / Driving</td>\n",
       "      <td>True</td>\n",
       "      <td>Namco</td>\n",
       "      <td>True</td>\n",
       "      <td>63</td>\n",
       "      <td>0.15</td>\n",
       "      <td>9.95</td>\n",
       "      <td>Nintendo DS</td>\n",
       "      <td>E</td>\n",
       "      <td>True</td>\n",
       "      <td>2004</td>\n",
       "      <td>2.233333</td>\n",
       "      <td>2.233333</td>\n",
       "      <td>2.233333</td>\n",
       "      <td>1</td>\n",
       "      <td>2.233333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.233333</td>\n",
       "      <td>2.233333</td>\n",
       "      <td>2.233333</td>\n",
       "      <td>1</td>\n",
       "      <td>2.233333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Darkstalkers Chronicle: The Chaos Tower</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Action</td>\n",
       "      <td>True</td>\n",
       "      <td>Capcom</td>\n",
       "      <td>True</td>\n",
       "      <td>74</td>\n",
       "      <td>0.14</td>\n",
       "      <td>14.95</td>\n",
       "      <td>Sony PSP</td>\n",
       "      <td>E</td>\n",
       "      <td>True</td>\n",
       "      <td>2004</td>\n",
       "      <td>1.633333</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>1.066667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.633333</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>1.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Ape Escape Academy</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Action,Sports</td>\n",
       "      <td>True</td>\n",
       "      <td>Sony</td>\n",
       "      <td>True</td>\n",
       "      <td>51</td>\n",
       "      <td>0.13</td>\n",
       "      <td>14.95</td>\n",
       "      <td>Sony PSP</td>\n",
       "      <td>E</td>\n",
       "      <td>True</td>\n",
       "      <td>2004</td>\n",
       "      <td>1.883333</td>\n",
       "      <td>1.883333</td>\n",
       "      <td>1.883333</td>\n",
       "      <td>1</td>\n",
       "      <td>1.883333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.883333</td>\n",
       "      <td>1.883333</td>\n",
       "      <td>1.883333</td>\n",
       "      <td>1</td>\n",
       "      <td>1.883333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Title  Features.Handheld?  \\\n",
       "0                         Super Mario 64 DS                True   \n",
       "1                    Lumines: Puzzle Fusion                True   \n",
       "2                        WarioWare Touched!                True   \n",
       "3                  Hot Shots Golf: Open Tee                True   \n",
       "4                              Spider-Man 2                True   \n",
       "5                The Urbz: Sims in the City                True   \n",
       "6                               Ridge Racer                True   \n",
       "7                           Metal Gear Ac!d                True   \n",
       "8                           Madden NFL 2005                True   \n",
       "9                               Pokmon Dash                True   \n",
       "10                         Dynasty Warriors                True   \n",
       "11                     Feel the Magic XY/XX                True   \n",
       "12                           Ridge Racer DS                True   \n",
       "13  Darkstalkers Chronicle: The Chaos Tower                True   \n",
       "14                       Ape Escape Academy                True   \n",
       "\n",
       "    Features.Max Players  Features.Multiplatform?  Features.Online?  \\\n",
       "0                      1                     True              True   \n",
       "1                      1                     True              True   \n",
       "2                      2                     True              True   \n",
       "3                      1                     True              True   \n",
       "4                      1                     True              True   \n",
       "5                      1                     True              True   \n",
       "6                      1                     True              True   \n",
       "7                      1                     True              True   \n",
       "8                      1                     True              True   \n",
       "9                      1                     True              True   \n",
       "10                     1                     True              True   \n",
       "11                     1                     True              True   \n",
       "12                     1                     True              True   \n",
       "13                     1                     True              True   \n",
       "14                     4                     True              True   \n",
       "\n",
       "                             Metadata.Genres  Metadata.Licensed?  \\\n",
       "0                                     Action                True   \n",
       "1                                   Strategy                True   \n",
       "2             Action,Racing / Driving,Sports                True   \n",
       "3                                     Sports                True   \n",
       "4                                     Action                True   \n",
       "5                                 Simulation                True   \n",
       "6                           Racing / Driving                True   \n",
       "7                                   Strategy                True   \n",
       "8                                     Sports                True   \n",
       "9                           Racing / Driving                True   \n",
       "10       Action,Adventure,Role-Playing (RPG)                True   \n",
       "11  Action,Adventure,Racing / Driving,Sports                True   \n",
       "12                          Racing / Driving                True   \n",
       "13                                    Action                True   \n",
       "14                             Action,Sports                True   \n",
       "\n",
       "   Metadata.Publishers  Metadata.Sequel?  Metrics.Review Score  Metrics.Sales  \\\n",
       "0             Nintendo              True                    85           4.69   \n",
       "1              Ubisoft              True                    89           0.56   \n",
       "2             Nintendo              True                    81           0.54   \n",
       "3                 Sony              True                    81           0.49   \n",
       "4           Activision              True                    61           0.45   \n",
       "5                   EA              True                    67           0.41   \n",
       "6                Namco              True                    88           0.36   \n",
       "7               Konami              True                    75           0.34   \n",
       "8                   EA              True                    68           0.25   \n",
       "9             Nintendo              True                    46           0.22   \n",
       "10                 NaN              True                    62           0.20   \n",
       "11                Sega              True                    75           0.16   \n",
       "12               Namco              True                    63           0.15   \n",
       "13              Capcom              True                    74           0.14   \n",
       "14                Sony              True                    51           0.13   \n",
       "\n",
       "    Metrics.Used Price Release.Console Release.Rating  Release.Re-release?  \\\n",
       "0                24.95     Nintendo DS              E                 True   \n",
       "1                14.95        Sony PSP              E                 True   \n",
       "2                22.95     Nintendo DS              E                 True   \n",
       "3                12.95        Sony PSP              E                 True   \n",
       "4                14.95     Nintendo DS              E                 True   \n",
       "5                12.95     Nintendo DS              M                 True   \n",
       "6                19.95        Sony PSP              E                 True   \n",
       "7                17.95        Sony PSP              E                 True   \n",
       "8                 8.95     Nintendo DS              T                 True   \n",
       "9                24.95     Nintendo DS              T                 True   \n",
       "10               14.95        Sony PSP              E                 True   \n",
       "11                8.95     Nintendo DS              T                 True   \n",
       "12                9.95     Nintendo DS              E                 True   \n",
       "13               14.95        Sony PSP              E                 True   \n",
       "14               14.95        Sony PSP              E                 True   \n",
       "\n",
       "    Release.Year  Length.All PlayStyles.Average  \\\n",
       "0           2004                      22.716667   \n",
       "1           2004                      10.100000   \n",
       "2           2004                       4.566667   \n",
       "3           2004                       0.000000   \n",
       "4           2004                      13.250000   \n",
       "5           2004                      21.933333   \n",
       "6           2004                       0.816667   \n",
       "7           2004                      25.383333   \n",
       "8           2004                       0.000000   \n",
       "9           2004                       3.833333   \n",
       "10          2004                       8.883333   \n",
       "11          2004                       2.900000   \n",
       "12          2004                       2.233333   \n",
       "13          2004                       1.633333   \n",
       "14          2004                       1.883333   \n",
       "\n",
       "    Length.All PlayStyles.Leisure  Length.All PlayStyles.Median  \\\n",
       "0                       31.900000                     24.483333   \n",
       "1                       11.016667                     10.000000   \n",
       "2                       11.566667                      2.500000   \n",
       "3                        0.000000                      0.000000   \n",
       "4                       48.383333                     10.000000   \n",
       "5                       25.500000                     20.000000   \n",
       "6                        1.050000                      0.883333   \n",
       "7                       51.650000                     21.266667   \n",
       "8                        0.000000                      0.000000   \n",
       "9                        7.250000                      1.183333   \n",
       "10                      18.050000                      2.083333   \n",
       "11                       3.800000                      3.000000   \n",
       "12                       2.233333                      2.233333   \n",
       "13                       2.400000                      2.000000   \n",
       "14                       1.883333                      1.883333   \n",
       "\n",
       "    Length.All PlayStyles.Polled  Length.All PlayStyles.Rushed  \\\n",
       "0                             57                     14.300000   \n",
       "1                              5                      9.516667   \n",
       "2                             57                      2.266667   \n",
       "3                              0                      0.000000   \n",
       "4                             37                      7.066667   \n",
       "5                              7                     16.733333   \n",
       "6                              6                      0.583333   \n",
       "7                             18                     19.166667   \n",
       "8                              0                      0.000000   \n",
       "9                              4                      1.750000   \n",
       "10                             4                      3.116667   \n",
       "11                             9                      2.316667   \n",
       "12                             1                      2.233333   \n",
       "13                             7                      1.066667   \n",
       "14                             1                      1.883333   \n",
       "\n",
       "    Length.Completionists.Average  Length.Completionists.Leisure  \\\n",
       "0                       29.766667                      35.033333   \n",
       "1                        0.000000                       0.000000   \n",
       "2                       10.000000                      14.100000   \n",
       "3                        0.000000                       0.000000   \n",
       "4                       72.566667                      78.866667   \n",
       "5                       30.033333                      30.033333   \n",
       "6                        1.250000                       1.250000   \n",
       "7                       80.000000                      80.000000   \n",
       "8                        0.000000                       0.000000   \n",
       "9                       12.000000                      12.000000   \n",
       "10                       0.000000                       0.000000   \n",
       "11                       0.000000                       0.000000   \n",
       "12                       0.000000                       0.000000   \n",
       "13                       0.000000                       0.000000   \n",
       "14                       0.000000                       0.000000   \n",
       "\n",
       "    Length.Completionists.Median  Length.Completionists.Polled  \\\n",
       "0                      30.000000                            20   \n",
       "1                       0.000000                             0   \n",
       "2                       7.250000                            16   \n",
       "3                       0.000000                             0   \n",
       "4                      72.566667                             2   \n",
       "5                      30.033333                             2   \n",
       "6                       1.250000                             1   \n",
       "7                      80.000000                             1   \n",
       "8                       0.000000                             0   \n",
       "9                      12.000000                             1   \n",
       "10                      0.000000                             0   \n",
       "11                      0.000000                             0   \n",
       "12                      0.000000                             0   \n",
       "13                      0.000000                             0   \n",
       "14                      0.000000                             0   \n",
       "\n",
       "    Length.Completionists.Rushed  Length.Main + Extras.Average  \\\n",
       "0                      22.016667                     24.916667   \n",
       "1                       0.000000                      9.750000   \n",
       "2                       6.800000                      3.850000   \n",
       "3                       0.000000                      0.000000   \n",
       "4                      66.283333                     12.766667   \n",
       "5                      30.033333                     20.833333   \n",
       "6                       1.250000                      0.883333   \n",
       "7                      80.000000                     24.833333   \n",
       "8                       0.000000                      0.000000   \n",
       "9                      12.000000                      0.000000   \n",
       "10                      0.000000                      0.000000   \n",
       "11                      0.000000                      3.100000   \n",
       "12                      0.000000                      0.000000   \n",
       "13                      0.000000                      0.000000   \n",
       "14                      0.000000                      0.000000   \n",
       "\n",
       "    Length.Main + Extras.Leisure  Length.Main + Extras.Median  \\\n",
       "0                      29.966667                    25.000000   \n",
       "1                       9.866667                     9.750000   \n",
       "2                       5.666667                     3.333333   \n",
       "3                       0.000000                     0.000000   \n",
       "4                      17.316667                    12.500000   \n",
       "5                      25.200000                    20.000000   \n",
       "6                       0.933333                     0.883333   \n",
       "7                      27.483333                    25.100000   \n",
       "8                       0.000000                     0.000000   \n",
       "9                       0.000000                     0.000000   \n",
       "10                      0.000000                     0.000000   \n",
       "11                      3.150000                     3.100000   \n",
       "12                      0.000000                     0.000000   \n",
       "13                      0.000000                     0.000000   \n",
       "14                      0.000000                     0.000000   \n",
       "\n",
       "    Length.Main + Extras.Polled  Length.Main + Extras.Rushed  \\\n",
       "0                            16                    18.333333   \n",
       "1                             2                     9.616667   \n",
       "2                            11                     2.783333   \n",
       "3                             0                     0.000000   \n",
       "4                            12                    10.483333   \n",
       "5                             3                    16.450000   \n",
       "6                             2                     0.833333   \n",
       "7                             6                    21.916667   \n",
       "8                             0                     0.000000   \n",
       "9                             0                     0.000000   \n",
       "10                            0                     0.000000   \n",
       "11                            2                     3.050000   \n",
       "12                            0                     0.000000   \n",
       "13                            0                     0.000000   \n",
       "14                            0                     0.000000   \n",
       "\n",
       "    Length.Main Story.Average  Length.Main Story.Leisure  \\\n",
       "0                   14.333333                  18.316667   \n",
       "1                   10.333333                  11.083333   \n",
       "2                    1.916667                   2.933333   \n",
       "3                    0.000000                   0.000000   \n",
       "4                    8.350000                  11.083333   \n",
       "5                   15.500000                  15.750000   \n",
       "6                    0.616667                   0.783333   \n",
       "7                   20.700000                  23.600000   \n",
       "8                    0.000000                   0.000000   \n",
       "9                    1.116667                   1.200000   \n",
       "10                   8.883333                  18.050000   \n",
       "11                   2.850000                   3.783333   \n",
       "12                   2.233333                   2.233333   \n",
       "13                   1.633333                   2.400000   \n",
       "14                   1.883333                   1.883333   \n",
       "\n",
       "    Length.Main Story.Median  Length.Main Story.Polled  \\\n",
       "0                  14.500000                        21   \n",
       "1                  10.000000                         3   \n",
       "2                   1.833333                        30   \n",
       "3                   0.000000                         0   \n",
       "4                   8.000000                        23   \n",
       "5                  15.500000                         2   \n",
       "6                   0.533333                         3   \n",
       "7                  20.783333                        11   \n",
       "8                   0.000000                         0   \n",
       "9                   1.083333                         3   \n",
       "10                  2.083333                         4   \n",
       "11                  2.983333                         7   \n",
       "12                  2.233333                         1   \n",
       "13                  2.000000                         7   \n",
       "14                  1.883333                         1   \n",
       "\n",
       "    Length.Main Story.Rushed  \n",
       "0                   9.700000  \n",
       "1                   9.583333  \n",
       "2                   1.433333  \n",
       "3                   0.000000  \n",
       "4                   5.333333  \n",
       "5                  15.250000  \n",
       "6                   0.450000  \n",
       "7                  17.883333  \n",
       "8                   0.000000  \n",
       "9                   1.050000  \n",
       "10                  3.116667  \n",
       "11                  2.300000  \n",
       "12                  2.233333  \n",
       "13                  1.066667  \n",
       "14                  1.883333  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2) printing a table with the first 15 samples\n",
    "pd.set_option('display.max_columns', None) # setting option to display all the columns\n",
    "df.head(15) # display the first 15 samples "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first line of this code snippet (`pd.set_option('display.max_columns', None)`) sets the option to display all the columns; the `df.head(X)` method displays the first `X` samples in the DataFrame `df`. In this case, it is possible to see the values of the first 15 instances for each possible feature.\n",
    "\n",
    "We can start watching at data composition and notice some characteristics. For example, the fact that the `Metadata.Genres` values can contain more comma-separated values (e.g. `Action,Adventure,Role-Playing (RPG)` means that the corresponding record has three genres: `Action`, `Adventure` and `Role-Playing (RPG)`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3) plotting the histogram distribution of \"Features.Handheld?\"\n",
    "df['Features.Handheld?'].value_counts().append(pd.Series([0], index=[False])).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to plot the histogram distribution of a feature `f`, we use the `value_counts()` method to get the count of unique occurrences in column `f` and then we plot the resulting series with the `plot(kind='bar')` method.\n",
    "\n",
    "Since all the instances `x` in the dataset have `x.Features.Handheld? = True`, we add a dummy false `Serie` (0 occurrences) in order to show both the values of the boolean feature in the resulting histogram. The resulting graph is pretty intuitive tough: this feature is not representative, i.e. it is not going to affect any prediction since all the instances have the same value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 4) plotting the histogram distribution of \"Features.Online?\"\n",
    "df['Features.Online?'].value_counts().append(pd.Series([0], index=[False])).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to plot the histogram distribution of a feature `f`, we use the `value_counts()` method to get the count of unique occurrences in column `f` and then we plot the resulting series with the `plot(kind='bar')` method.\n",
    "\n",
    "Since all the instances `x` in the dataset have `x.Features.Online? = True`, we add a dummy false `Serie` (0 occurrences) in order to show both the values of the boolean feature in the resulting histogram. Even in this case, the resulting graph is pretty intuitive and the corresponding feature is not representative, i.e. it is not going to affect any prediction since all the instances have the same value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5) plotting the histogram distribution of \"Metadata.Publishers\"\n",
    "df['Metadata.Publishers'].value_counts().plot(kind='bar', figsize=(20,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method to plot the histogram distribution of a feature is still the same. In this case, however, we do not add a dummy `Serie` since this feature is not boolean but instead it is categorical. Printing `set(df['Metadata.Publishers'].values)`, we can see that there are 32 possible string values:\n",
    "\n",
    "`{nan, 'THQ', 'EA,Namco', 'Sega', 'Microsoft', 'Activision', 'EA', 'Capcom', 'Ubisoft', 'Sony', 'SquareEnix', 'Capcom,Nintendo', 'Capcom,Rockstar', '2K', 'Disney', 'Atari,Namco', 'EA,Sony', 'Namco,Sony', 'Eidos', 'Microsoft,SquareEnix', 'Nintendo', 'Activision,Konami', 'Nintendo,Sega', 'Nintendo,SquareEnix', 'Rockstar', 'Namco,Ubisoft', 'Konami', 'Activision,Sony', 'Atari', 'Sony,Ubisoft', 'Namco', 'Midway'}`\n",
    "\n",
    "The first observations we can make are the following ones:\n",
    "- we are going to need to deal with the `nan` values (representing a non-specified value for the `Metadata.Publishers` feature) which are not plotted in the histogram above;\n",
    "- some values are just the joint string of two publishers; e.g. the instances with `Metadata.Publishers='Activision,Konami'` can be considered to have two publishers: `Activision` and `Konami○`. We are going to consider these cases during encoding of categorical features \\[see next Section\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Feature Name  Feature importance\n",
      "0                  Features.Handheld?            0.000000\n",
      "1                Features.Max Players            0.007109\n",
      "2             Features.Multiplatform?            0.000000\n",
      "3                    Features.Online?            0.000000\n",
      "4                  Metadata.Licensed?            0.000000\n",
      "5                    Metadata.Sequel?            0.000000\n",
      "6                       Metrics.Sales            0.147991\n",
      "7                  Metrics.Used Price            0.043757\n",
      "8                 Release.Re-release?            0.000000\n",
      "9                        Release.Year            0.017377\n",
      "10      Length.All PlayStyles.Average            0.011087\n",
      "11      Length.All PlayStyles.Leisure            0.025058\n",
      "12       Length.All PlayStyles.Median            0.061857\n",
      "13       Length.All PlayStyles.Polled            0.013374\n",
      "14       Length.All PlayStyles.Rushed            0.013124\n",
      "15      Length.Completionists.Average            0.007686\n",
      "16      Length.Completionists.Leisure            0.017048\n",
      "17       Length.Completionists.Median            0.026475\n",
      "18       Length.Completionists.Polled            0.011284\n",
      "19       Length.Completionists.Rushed            0.030068\n",
      "20       Length.Main + Extras.Average            0.007424\n",
      "21       Length.Main + Extras.Leisure            0.009360\n",
      "22        Length.Main + Extras.Median            0.017329\n",
      "23        Length.Main + Extras.Polled            0.205204\n",
      "24        Length.Main + Extras.Rushed            0.014180\n",
      "25          Length.Main Story.Average            0.009298\n",
      "26          Length.Main Story.Leisure            0.017379\n",
      "27           Length.Main Story.Median            0.007924\n",
      "28           Length.Main Story.Polled            0.024062\n",
      "29           Length.Main Story.Rushed            0.020394\n",
      "30              Metadata.Publisher 2K            0.013422\n",
      "31      Metadata.Publisher Activision            0.011759\n",
      "32           Metadata.Publisher Atari            0.008040\n",
      "33          Metadata.Publisher Capcom            0.004258\n",
      "34          Metadata.Publisher Disney            0.001359\n",
      "35              Metadata.Publisher EA            0.013849\n",
      "36           Metadata.Publisher Eidos            0.000109\n",
      "37          Metadata.Publisher Konami            0.006870\n",
      "38       Metadata.Publisher Microsoft            0.004629\n",
      "39          Metadata.Publisher Midway            0.001362\n",
      "40           Metadata.Publisher Namco            0.000398\n",
      "41        Metadata.Publisher Nintendo            0.006368\n",
      "42        Metadata.Publisher Rockstar            0.000000\n",
      "43            Metadata.Publisher Sega            0.000577\n",
      "44            Metadata.Publisher Sony            0.008683\n",
      "45      Metadata.Publisher SquareEnix            0.006538\n",
      "46             Metadata.Publisher THQ            0.005011\n",
      "47         Metadata.Publisher Ubisoft            0.004302\n",
      "48              Metadata.Genre Action            0.014090\n",
      "49           Metadata.Genre Adventure            0.001571\n",
      "50         Metadata.Genre Educational            0.000095\n",
      "51    Metadata.Genre Racing / Driving            0.006018\n",
      "52  Metadata.Genre Role-Playing (RPG)            0.006922\n",
      "53          Metadata.Genre Simulation            0.006021\n",
      "54              Metadata.Genre Sports            0.022785\n",
      "55            Metadata.Genre Strategy            0.010277\n",
      "56        Release.Console_Nintendo DS            0.006908\n",
      "57       Release.Console_Nintendo Wii            0.026647\n",
      "58      Release.Console_PlayStation 3            0.004281\n",
      "59           Release.Console_Sony PSP            0.008473\n",
      "60               Release.Console_X360            0.001385\n",
      "61                   Release.Rating_E            0.010774\n",
      "62                   Release.Rating_M            0.004903\n",
      "63                   Release.Rating_T            0.005469\n"
     ]
    }
   ],
   "source": [
    "# 6) perform feature importance analysis\n",
    "# method with decision trees\n",
    "\n",
    "from sklearn import tree\n",
    "\n",
    "# removing 'Title' column\n",
    "df_fi = df.drop(['Title'], axis=1)\n",
    "# obtaining dummy columns to encode 'Metadata.Publishers' feature\n",
    "dummy_publishers = df_fi['Metadata.Publishers'].str.get_dummies(sep=',').add_prefix('Metadata.Publisher ')\n",
    "# obtaining dummy columns to encode 'Metadata.Genres' feature\n",
    "dummy_genres = df_fi['Metadata.Genres'].str.get_dummies(sep=',').add_prefix('Metadata.Genre ')\n",
    "\n",
    "df_fi = pd.concat([df_fi, dummy_publishers, dummy_genres], axis=1)\n",
    "df_fi.drop(['Metadata.Publisher nan', 'Metadata.Publishers', 'Metadata.Genres'], axis=1, inplace=True)\n",
    "\n",
    "for feature in df_fi:\n",
    "    # remove missing values imputing NaN with most frequent value in the column\n",
    "    df_fi[feature].fillna(df_fi[feature].mode(1)[0], inplace=True)\n",
    "\n",
    "    # encoding all the remaining categorical features with \"classic\" one-hot encoding\n",
    "    if df_fi[feature].dtype.name == \"category\":\n",
    "        new_columns = pd.get_dummies(df_fi[feature], prefix=feature)\n",
    "        df_fi.drop([feature], axis=1, inplace=True) # drop the original feature column\n",
    "        df_fi = pd.concat([df_fi, new_columns], axis=1) # concat new columns with the original df_fi\n",
    "\n",
    "# training to predict 'Metrics.Review Score'\n",
    "reg = tree.DecisionTreeRegressor()\n",
    "X = df_fi.drop([\"Metrics.Review Score\"], axis=1)\n",
    "y = df_fi[\"Metrics.Review Score\"]\n",
    "reg.fit(X, y)\n",
    "\n",
    "# printing feature importances\n",
    "name_to_importance = pd.DataFrame({'Feature Name': X.columns, 'Feature importance': reg.feature_importances_})\n",
    "pd.set_option('display.max_rows', None)\n",
    "print(name_to_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to evaluate feature importances with a decision tree. In particular, since in this case the target feature is continuous, we are going to train a `DecisionTreeRegressor`. The `DecisionTreeRegressor` class of Scikit Learn library does not accept categorical features. Therefore, we need to deal with the string columns in the dataframe. We do such preprocessing here and we will reuse the new dataframe obtained also in the following sections since even the other algorithms that are going to be used do not accept categorical features.\n",
    "\n",
    "The categorical features in the videogames dataset are the following ones:\n",
    "- `Title`\n",
    "- `Metadata.Genres`\n",
    "- `Metadata.Publishers`\n",
    "- `Release.Console`\n",
    "- `Release.Rating`\n",
    "\n",
    "The simplest way to encode a categorical feature is **label encoding**: each possible value of the categorical feature is simply converted to a number. In order to label-encode a feature `f` with `pandas`, we could simply execute: `df[f] = df[f].cat.codes`\n",
    "\n",
    "The problem with this approach is that the numeric values can be misinterpreted by algorithms as having some sort of hierarchy/order in them. This is quite evident in Decision Trees, which would split the data without any sense if the categorical feature is not ordinal. The only categorical feature in our dataset which has an order is the `Release.Rating` one, but as we are going to see the problem lies in the other ones. Therefore we need to use another approach for the others, which is **one-hot encoding**. \n",
    "\n",
    "Since we are going to substitute the column of the feature `f` with a set of `m` columns (where `m` is the number of possible values for `f`), let's take a look to the number of possible values that each categorical feature can have, printing `len(set(df[f]))` for each feature `f`:\n",
    "\n",
    "- `len(set(df_fi[\"Title\"])) = 908`\n",
    "- `len(set(df_fi[\"Metadata.Genres\"])) = 48`\n",
    "- `len(set(df_fi[\"Metadata.Publishers\"])) = 32`\n",
    "- `len(set(df_fi[\"Release.Console\"])) = 5`\n",
    "- `len(set(df_fi[\"Release.Rating\"])) = 3`\n",
    "\n",
    "`len(set(df[f]))` is equal to the number of different values in the column `f`, i.e. the number of columns in a dummy one-hot encoding. If these numbers are too large, we could have too many features that would lead to an explosion in the training time and space. Therefore, we obviously cannot one-hot encode `Title`, `Metadata.Genres` and `Metadata.Publishers` as they are.\n",
    "\n",
    "First of all, we are going to exclude the `Title` column because it has more than 900 possible values, and a one-hot encoding would lead to having more than 900 features; moreover, label encoding cannot be used because there is no order in titles and decision tree would end up with splits that do not make sense. It could have some importance in the prediction of the target feature, since we have some repeated values that could be representative, but the cost is too high for a very small information gain, therefore I preferred to discard this column.\n",
    "\n",
    "Let's consider the `Metadata.Genres` and `Metadata.Publishers` features. They both have a big number of possible values but we already noticed in Section 2.2 (2nd request) that values in `Metadata.Genres` feature can be composed by a string of more genres, separated by a comma. The same can be said by studying values of the `Metadata.Publishers` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possible genres:\n",
      "{'Action,Racing / Driving', 'Racing / Driving,Simulation,Sports', 'Action,Role-Playing (RPG),Strategy', 'Simulation,Sports', 'Racing / Driving,Simulation', 'Role-Playing (RPG),Simulation', 'Adventure,Simulation,Sports', 'Adventure,Educational,Strategy', 'Action,Adventure', 'Action,Simulation,Strategy', 'Adventure,Role-Playing (RPG),Strategy', 'Action,Educational', 'Action,Role-Playing (RPG),Simulation,Sports,Strategy', 'Educational,Simulation', 'Action,Strategy', 'Action,Adventure,Racing / Driving,Sports', 'Adventure,Simulation', 'Role-Playing (RPG),Simulation,Strategy', 'Sports', 'Racing / Driving', 'Educational,Sports', 'Adventure,Role-Playing (RPG)', 'Action', 'Action,Racing / Driving,Role-Playing (RPG)', 'Action,Role-Playing (RPG)', 'Racing / Driving,Simulation,Strategy', 'Action,Racing / Driving,Sports,Strategy', 'Action,Adventure,Strategy', 'Educational,Strategy', 'Action,Simulation,Sports', 'Simulation', 'Sports,Strategy', 'Role-Playing (RPG)', 'Action,Racing / Driving,Role-Playing (RPG),Strategy', 'Educational', 'Racing / Driving,Sports', 'Action,Simulation', 'Simulation,Strategy', 'Role-Playing (RPG),Strategy', 'Action,Sports', 'Adventure', 'Action,Adventure,Role-Playing (RPG)', 'Action,Racing / Driving,Simulation', 'Simulation,Sports,Strategy', 'Strategy', 'Action,Adventure,Racing / Driving', 'Action,Racing / Driving,Sports', 'Action,Role-Playing (RPG),Simulation'}\n",
      "\n",
      "Possible publishers:\n",
      "{'Namco', nan, 'Eidos', 'Disney', 'EA', 'Capcom', 'Microsoft,SquareEnix', '2K', 'Capcom,Nintendo', 'Activision,Konami', 'THQ', 'Ubisoft', 'Namco,Sony', 'Atari', 'Nintendo,SquareEnix', 'Atari,Namco', 'Nintendo,Sega', 'Sony', 'Microsoft', 'Capcom,Rockstar', 'SquareEnix', 'Sega', 'Midway', 'Nintendo', 'Sony,Ubisoft', 'EA,Sony', 'Activision', 'Namco,Ubisoft', 'EA,Namco', 'Konami', 'Activision,Sony', 'Rockstar'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Possible genres:\")\n",
    "print(set(df['Metadata.Genres']))\n",
    "print(\"\\nPossible publishers:\")\n",
    "print(set(df['Metadata.Publishers']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 8 genres, the other possible values are just concatenation of these 8 genres. Therefore, we encode the `Metadata.Genres` to 8 binary features, and a record with genre = `Action,Racing / Driving,Role-Playing (RPG)` will have 1 in `Metadata.Genre Action`, `Metadata.Genre Racing / Driving` and `Metadata.Genre Role-Playing (RPG)` columns. In order to do that, we simply execute the following line of code:\n",
    "\n",
    "`df_fi['Metadata.Genres'].str.get_dummies(sep=',').add_prefix('Metadata.Genre ')`\n",
    "\n",
    "which returns the dummy columns for genres splitting each value of the feature on the comma and adding the prefix \"Metadata.Genre \" to the column name just for clarity. Finally, the obtained columns are concatenated to the original dataframe and the original `Metadata.Genres` column is dropped.\n",
    "\n",
    "The same process is repeated for the `Metadata.Publishers` column, except for one difference: since in the possible publishers there is also the `nan` value, which denotes the missing of the publisher in that particular record, the final list of dummy columns will contain also the `Metadata.Publisher nan` column. This column is going to be enhanced to 1 for the records that have no publisher, but it can be noticed that it is exactly the same case in which all publisher columns are 0. Therefore, no more information is added by this column and can be dropped out. In this case, moreover, we can prevent imputation on the `Metadata.Publishers` column, that would have resulted in fictitious values.\n",
    "\n",
    "For the remaining categorical features (`Release.Console` and `Release.Rating`) we can proceed with the classic one-hot encoding that will result in 8 new columns (5 for the consoles and 3 for the ratings).\n",
    "\n",
    "Finally, all the missing values are managed substituing them with the most frequent value in the corresponding column. This allows to use the same strategy for all the columns.\n",
    "\n",
    "After encoding of categorical features and imputation of `NaN` values, we can proceed with the training of a `DecisionTreeRegressor` with `Metrics.Review Score` as the target feature. All the data is used for fitting and no other pre-processing actions are carried out. After that, we simply print the feature importance formatting the feature names and importances with a dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## 3. Classification (up to 7/8 points)\n",
    "In this part of the tutorial you are requested to perform all the necessary steps required in order to design a full fledged classification task on the <b>Metrics.Review Score</b>.\n",
    "\n",
    "You are requested to perform the following steps having in mind the following: \n",
    "\n",
    "1) the dataset must be properly splitted to perform crossvalidation during model selection/hyper parameter tuning and to test during the evaluation step \n",
    "\n",
    "2) features must be properly encoded\n",
    "\n",
    "3) the target feature can be dicretized <b>(number of classes must be greater than 5)</b> in order to simplify the problem;\n",
    "\n",
    "4) for model selection you are requested to consider: \n",
    "    - Decision Trees\n",
    "    - Support Vector Machines;\n",
    "    - An ensamble methodology;\n",
    "    - MLPNs.\n",
    "    \n",
    "5) during model selection hyper-parameter tuning must be performed and discussed;\n",
    "\n",
    "6) class imbalancing must be addressed (when appropriate);\n",
    "\n",
    "7) remember to apply standardizion and normalization when appropriate;\n",
    "\n",
    "8) provide a discussion of model selection where you describe the differences in terms of performance and explains the root causes;\n",
    "\n",
    "9) describe the measure adopted for the evaluation and discuss the results;\n",
    "\n",
    "#### 3.1 Preprocessing (up to 2/8 points)\n",
    "Write the necessary code to perfrom an adequate prepocessing, <b>REMEMBER to describe with your own words each step. Perfectly working code with no comments and discussion correpsonds to 0 POINTS</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) features must be properly encoded\n",
    "# missing values must be managed\n",
    "df_c = df_fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first part of preprocessing, we should properly encode features and, in particular, categorical ones. Moreover, we should also deal with missing values. However, these two preprocessing tasks have been carried out during the last part of Section 2.2 for the Dataset Analysis and the processes have been explained deeply in the previous cells. Therefore, we are just going to use the `df_fi` dataframe also for this part of the challenge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0            Very high\n",
      "1       Extremely high\n",
      "2            Very high\n",
      "3            Very high\n",
      "4               Medium\n",
      "             ...      \n",
      "1207              High\n",
      "1208            Medium\n",
      "1209               Low\n",
      "1210            Medium\n",
      "1211          Very low\n",
      "Name: Metrics.Review Score, Length: 1212, dtype: category\n",
      "Categories (7, object): ['Extremely low' < 'Very low' < 'Low' < 'Medium' < 'High' < 'Very high' < 'Extremely high']\n"
     ]
    }
   ],
   "source": [
    "# 3) the target feature (Metrics.Review Score) can be dicretized (number of classes must be greater than 5)\n",
    "# in order to simplify the problem\n",
    "\n",
    "df_c[\"Metrics.Review Score\"] = pd.cut(\n",
    "    df_c[\"Metrics.Review Score\"],\n",
    "    7,\n",
    "    labels = ['Extremely low', 'Very low', 'Low', 'Medium', 'High', 'Very high', 'Extremely high']\n",
    ")\n",
    "pd.set_option('display.max_rows', 20)\n",
    "print(df_c[\"Metrics.Review Score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target feature (`Metrics.Review Score`) is dicretized in order to simplify the problem. The cut function is used to segment and sort data values into bins. The input array to be binned is the 1-dimensional list of DataFrame corresponding to `Metrics.Review Score` feature; the `bins` parameter is set to 7 in order to have more than 5 classes and labels name are specified for clarity: `Extremely low`, `Very low`, `Low`, `Medium`, `High`, `Very high` and `Extremely high`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Very high': 406, 'Extremely high': 406, 'Medium': 406, 'High': 406, 'Low': 406, 'Very low': 406, 'Extremely low': 406})\n"
     ]
    }
   ],
   "source": [
    "# 6) class imbalancing must be addressed (when appropriate);\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "X = df_c.drop(\"Metrics.Review Score\", axis=1)\n",
    "y = df_c[\"Metrics.Review Score\"]\n",
    "X, y = SMOTE().fit_resample(X, y)\n",
    "\n",
    "counter = Counter(y)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classes of the target features are unbalanced, as we can see calling\n",
    "`df_c[\"Metrics.Review Score\"].value_counts()`:\n",
    "\n",
    "`High              406\n",
    "Very high         329\n",
    "Medium            263\n",
    "Low               114\n",
    "Extremely high     67\n",
    "Very low           25\n",
    "Extremely low       8`\n",
    "\n",
    "For example, there are 406 instances for the `High` class and only 8 for the `Extremely low` one. Therefore, we need to oversample the minority classes or undersample the majority classes. Since the loss of data should be always prevented, the first approach is preferred. Using **SMOTE** (Synthetic Minority Oversampling Technique), moreover, new instances can be synthetically created, instead of just duplicate examples (which would not add any new information to the model). In order to do this, we use the `SMOTE` class of the `imbalanced-learn` library.\n",
    "\n",
    "The total number of instances now becomes: `406*7 = 2842`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of instances is: 2842\n"
     ]
    }
   ],
   "source": [
    "print(f\"The total number of instances is: {X.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) the dataset must be properly split to perform crossvalidation during model selection/hyper parameter tuning\n",
    "# and to test during the evaluation step\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to perform cross-validation during model selection and HPs tuning, we are going to use `GridSearchCV` and `RandomizedSearchCV` classes that automatically split the set passed to the `fit` method and select one subset for testing from time to time.\n",
    "\n",
    "Instead, we now split the dataset into two parts by simply using the `train_test_split` function specifying that the test set is going to be about one-third of the data. It will be used in the final evaluation step, while the remaining 67% of the dataset is going to be used to train models and perform cv for the HPs tuning in the model selection phase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Model Selection  (up to 3/8 points)\n",
    "Write the necessary code to perfrom an adequate model selection. tips: for some models you may need to perform additional preprocessing steps (encoding, normalization, feature selection, class balancement, ...).\n",
    "<b>REMEMBER to describe with your own words each step. Perfectly working code with no comments and discussion correpsonds to 0 POINTS</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) model selection, considering: Decision Trees, Support Vector Machines, An ensamble methodology and MLPNs\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# 5) during model selection hyper-parameter tuning must be performed and discussed\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to select the best model, we are going to train Decision trees, SVMs, Random Forests and MLPNs. Each algorithm will be used with different hyperparameters, using `GridSearchCV` and `RandomizedSearchCV` classes to tune the best ones.\n",
    "\n",
    "First of all, we need to specify a list of configurations of possible parameters. Each configuration is a dictionary in which the key is the parameter name and the value is a list of settings to try for that parameter. In the following code, we are going to use just one configuration, i.e. a model will be trained for each possible combination of parameters in the configuration. In order to decide what parameters to add and what settings to try, I read the official documentation for each algorithm and I selected the most important parameters, based also on the studied theory:\n",
    "[DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html),\n",
    "[SVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html),\n",
    "[RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) and\n",
    "[MLPClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html).\n",
    "\n",
    "The tuning is performed using cross-validation, therefore each model is trained with a part of the training set and the performances are tested with one of the different folds the training set has been split into.\n",
    "\n",
    "Secondly, we need to create a `GridSearchCV` or a `RandomizedSearchCV` object. In case the tuning time is too long, we should prefer the latter. That is the case of MLPNs, in which parameters are a lot and time expensive. In order to further reduce the time for tuning, other parameters of `GridSearchCV` and `RandomizedSearchCV` are specified:\n",
    "- `cv = 3` which sets the number of folds to 3 instead of the default of 5;\n",
    "- `n_jobs = -1` in order to exploit all the cores (the `-1` value denotes that the number of jobs to run in parallel is equal to the number of processors).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'criterion': 'entropy', 'max_depth': 40, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "Best score: 0.6444343141317862\n"
     ]
    }
   ],
   "source": [
    "''' DECISION TREE '''\n",
    "\n",
    "possible_parameters = {\n",
    "    'criterion' : ['gini', 'entropy'],\n",
    "    'splitter'  : ['best', 'random'],\n",
    "    'max_depth' : [None, 3, 8, 15, 25, 40, 60],\n",
    "    'min_samples_split' : [2, 5, 10],\n",
    "    'min_samples_leaf'  : [1, 2, 3],\n",
    "    'max_features' : ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "dt_clf = GridSearchCV(\n",
    "    tree.DecisionTreeClassifier(), possible_parameters, scoring='accuracy', n_jobs=-1\n",
    ")\n",
    "\n",
    "dt_clf.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best params: {dt_clf.best_params_}\")\n",
    "print(f\"Best score: {dt_clf.best_score_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test both `criterion` and `splitter`, since these two parameters really affect the construction of the tree, by putting the two possible values for each. About the `max_depth` parameter, in addition to the `None` value (which corresponds to the maximum depth possible, 64 in this case) we add a few values with an exponential incrementation in order to test different depths and prevent overfitting (too deep trees). Indeed, the best classifier has `max_depth = 60`, which the biggest parameter but not the max depth possible. Finally, we test also some values for the splitting technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "Best score: 0.6228967435852854\n",
      "\n"
     ]
    }
   ],
   "source": [
    "''' SUPPORT VECTOR MACHINE '''\n",
    "# 7) remember to apply standardizion and normalization when appropriate\n",
    "from sklearn import preprocessing\n",
    "\n",
    "possible_parameters = {\n",
    "    'C': [1, 10, 100, 1000],\n",
    "    'gamma': [0.001, 0.01, 0.1, 1],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "svm_clf = GridSearchCV(\n",
    "    svm.SVC(), possible_parameters, cv=3, n_jobs=-1, scoring='accuracy'\n",
    ")\n",
    "\n",
    "# before fitting the model, we need to scale the training data\n",
    "X_train_scaled = preprocessing.scale(X_train)\n",
    "svm_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"Best params: {svm_clf.best_params_}\")\n",
    "print(f\"Best score: {svm_clf.best_score_}\")\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of SVMs, we need to scale the data before fitting the `GridSearchCV` because the RBF kernel assumes that all features are centred around zero and have variance in the same order. In this case, a standard scaling approach is used.\n",
    "\n",
    "The regularization parameter `C` must be tuned since it can really affect the performance of the machines. Moreover, a few values for the gamma parameter and four kernels are also put in the possible parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'criterion': 'entropy', 'max_depth': 60, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 1000}\n",
      "Best score: 0.7311044321352576\n"
     ]
    }
   ],
   "source": [
    "''' RANDOM FOREST '''\n",
    "\n",
    "possible_parameters = {\n",
    "    'n_estimators' : [100, 1000],\n",
    "    'criterion' : ['gini', 'entropy'],\n",
    "    'max_depth' : [None, 3, 8, 15, 25, 40, 60],\n",
    "    'min_samples_split' : [2, 5, 10],\n",
    "    'min_samples_leaf'  : [1, 2, 3],\n",
    "    'max_features' : ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "rf_clf = GridSearchCV(\n",
    "    RandomForestClassifier(), possible_parameters, cv=3, n_jobs=-1, scoring='accuracy'\n",
    ")\n",
    "\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best params: {rf_clf.best_params_}\")\n",
    "print(f\"Best score: {rf_clf.best_score_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are ensambling different decision trees, the possible parameters that have been selected are the same described for the previous training. In addition, we tune also the `n_estimators` parameter, which corresponds to the number of decision trees we want to ensemble. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'hidden_layer_sizes': (1000,), 'activation': 'relu'}\n",
      "Best score: 0.6601947782842934\n"
     ]
    }
   ],
   "source": [
    "''' MLPN '''\n",
    "\n",
    "possible_parameters = {\n",
    "    'activation' : ['logistic', 'tanh', 'relu'],\n",
    "    'hidden_layer_sizes': [ (5,), (50,), (100,), (1000,)]\n",
    "}\n",
    "\n",
    "nn_clf = RandomizedSearchCV(\n",
    "    MLPClassifier(max_iter=3000, learning_rate='adaptive'), possible_parameters, scoring='accuracy', n_jobs=-1\n",
    ")\n",
    "\n",
    "# using scaled trainset\n",
    "nn_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"Best params: {nn_clf.best_params_}\")\n",
    "print(f\"Best score: {nn_clf.best_score_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also **Multi-layer Perceptron** is sensitive to feature scaling, that is why we use the same trainset as before, obtained by using standard scaling. Of course, in order to get meaningful results, we must apply scaling even to the test set. However, in this phase is not necessary because the testing phase is applied to one of the subset in which `X_train_scaled` is split during cross-validation. Scaling should be applied also to the test set during the next Evaluation phase if the selected model is going to be the SVM or the MLPN.\n",
    "\n",
    "Some parameters have been fixed in the creation of the `RandomizedSearchCV` object (maximum number of iterations and the learning rate) since they affect the convergence of the training loss rather than the metrics and it was necessary to reduce execution times and prevent divergence. Using `learning_rate='adaptive'`, the value of the learning rate is reduced as soon as the training loss stops decreasing.\n",
    "\n",
    "About possible parameters selection, we obviously have to specify all the activation functions (except the identity one) because this is an important aspect of the neural networks. Moreover, we should also try different sizes for the hidden layers (in this case, only one hidden layer is selected)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Evaluation (up to 2/8 points)\n",
    "Write the necessary code to perform an adequate model evaluation of the selected model. Confusion matrix and classsification reports are welcome. \n",
    "<b>REMEMBER to describe with your own words each step. Perfectly working code with no comments and no discussion correpsonds to 0 POINTS</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8) provide a discussion of model selection where you describe the differences in terms of performance\n",
    "# and explains the root causes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you create a `GridSearchCV` or a `RandomizedSearchCV`, you can choose one single score trough which different models are compared. Of course, the process can be repeated with different metrics and selecting precision and recall would have probably given more information about the models' behaviour. However, in order to reduce the time of computation, I decided to use just accuracy. This is possible since the classes have been balanced and they all have (more or less) the same number of instances. *Note: they do not have exactly the same number instances even after SMOTE resampling because the `train_test_split` method split the dataset randomly and not taking into account the different classes. That can be verified by simply printing the `Counter` of `y_train` instead of all `y` set as done before:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Very high': 280, 'Extremely high': 279, 'Extremely low': 278, 'Low': 277, 'Medium': 264, 'High': 263, 'Very low': 263})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anyway, the number of instances is quite similar and accuracy is going to represent the percentage of correct predictions on the total.\n",
    "\n",
    "I also executed all the code for model selection putting `scoring = f1_micro`  in the creation of the `GridSearchCV` or `RandomizedSearchCV` object in order to take into account also precision and recall. The results were very similar.\n",
    "\n",
    "The models for each algorithm are going to be compared using the chosen scoring, because during the cross-validation process there will always be a subset chosen as testset on which to compute this score. The best estimator will be the one with the highest accuracy. After each fitting, the best score is printed and we can therefore select the model with best performance. Testing more combinations of parameters for all the algorithms would have possibly led to better results. However, for the aim of this project the result are encouraging and the best RandomForestClassifier reaches more than 70% of accuracy with an huge number of estimators (1000). Let's focus on this model for evaluation then."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "Extremely high       0.90      0.97      0.93       127\n",
      " Extremely low       0.99      0.98      0.99       128\n",
      "          High       0.62      0.44      0.51       143\n",
      "           Low       0.72      0.88      0.79       129\n",
      "        Medium       0.61      0.60      0.60       142\n",
      "     Very high       0.70      0.67      0.69       126\n",
      "      Very low       0.90      0.96      0.93       143\n",
      "\n",
      "      accuracy                           0.78       938\n",
      "     macro avg       0.78      0.79      0.78       938\n",
      "  weighted avg       0.77      0.78      0.77       938\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#9) describe the measure adopted for the evaluation and discuss the results\n",
    "\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "classifier = rf_clf.best_estimator_\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier we are evaluating is the best estimator obtained during HPs tuning phase for RandomForest classifiers. We are going to use the `predict` method to produce a list of predictions of the selected classifier on the `X_test` testset. These predictions must be compared with the ground truth (the `y_test` list of classes) and we can use the `classification_report` to show an overall report of the evaluation phase.\n",
    "\n",
    "As we said before, the corresponding model was able to correctly classify more than the 70% of all the instances during the cross-validation phase. We expect better results evaluating it on a new set of data, otherwise that would be an overfitting signal.\n",
    "\n",
    "In fact, the average accuracy is about 75%. In this case, we can also see other metrics (precision, recall and f-1 score) and even the number of occurrences of each class in `y_test`. It is important to study these results in order to understand how the prediction could be improved. As we can notice, the best-predicted class is the `Extremely low` with 95% of precision and 96% of recall, but even `Very low` and `Extremely high` classes have excellent results. If we remember from Section 3.1 when we addressed class imbalancing, the instances were distributed between the seven class in the following way:\n",
    "\n",
    "`\n",
    "High              406\n",
    "Very high         329\n",
    "Medium            263\n",
    "Low               114\n",
    "Extremely high     67\n",
    "Very low           25\n",
    "Extremely low       8\n",
    "`\n",
    "\n",
    "As we can see, the three classes that have a very low number of instances are indeed `Extremely low`, `Very low` and `Extremely high` and then we can notice that the metrics are higher for minor classes. This is quite intuitive, since the minor classes were synthetically oversampled and therefore the majority of the instances for these three classes are fake and probably over-represented. In the end, the good results depend mostly on the big similarity between instances of the minor classes. As proof of this, the class with the worst results is `High` which had the biggest number of \"original\" instances. These observations show that results are not completely reliable since the oversampling affects too much predictions. However, we know that the 60% of the games with an `High` review score (that are real instances) has been correctly classified. This is not an excellent result, but it not even bad since each instance has about 14% of probability to be randomly labelled with the correct class.\n",
    "\n",
    "It is possible that collecting new data for minor classes would lead to better results on the major classes. In fact, even if the average accuracy could decrease (due to the fact the the minor classes are probably going to have worse peformance with \"real\" data), I expect more balanced results between the different classes in case no instances have been sintetically generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Low': 158, 'Very low': 153, 'Medium': 139, 'Extremely high': 137, 'Extremely low': 127, 'Very high': 122, 'High': 102})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this Machine Learning challenge is to follow the ML workflow and build a model which can predict how likely a video game is going to be a blockbuster. The solutions depend on the single and specific requests.\n",
    "\n",
    "In the first part of the challenge, the dataset is loaded and analysed. We use DataFrame both because it was requested and because it is a very simple way to manage a dataset, better than any numpy data structure. A simple method is called to read the csv containing all the data, and its header is used to name the columns. The features of the dataset are 36 and their names and types can be seen in the `Out [2]` cell. \n",
    "\n",
    "The dtypes of five features (`Title`, `Metadata.Genres`, `Metadata.Publishers`, `Release.Console`, `Release.Console` and `Release.Rating`) have been changed from `object` to `category` just for clarity; in both cases, corresponding columns must be considered categorical, that means their values are strings. Categorical features are not accepted by some training algorithms, but we are going to address this problem in the Preprocessing section. The majority of features is numerical but we have also some boolean.\n",
    "\n",
    "Following the guidelines, the **Dataset Analysis** part contains some feature plots and a few prints to understand how the dataset is composed and structured. The dataset contains 1212 instances, and printing the first 15 ones we can also understand the meaning of each column and start noticing that:\n",
    "- some values are missing (we are going to need to deal with `Nan` values);\n",
    "- the `Metadata.Genres` column contains more comma-separated values (e.g. `Action,Adventure,Role-Playing (RPG)` means that the corresponding record has three genres: `Action`, `Adventure` and `Role-Playing (RPG)`).\n",
    "\n",
    "The same behaviour can be observed for the `Metadata.Publishers` feature, watching the plot in the `Out [7]` cell. Even in this case, some strings are single publishers (like `EA` or `Ubisoft`) while some others contains more companies (e.g. the instances with `Metadata.Publishers='Activision,Konami'` can be considered to have two publishers: `Activision` and `Konami○`). We are going to consider both cases during encoding of categorical features.\n",
    "\n",
    "The two boolean plotted features (`Features.Handheld?` and ` Features.Online?`) are useless. It can be easily inferred from the fact that all the instances have the same value `True`. Therefore, we could easily remove both the columns without losing any discriminant information. There is also an empirical evidence of the futility of these two features watching their importance according to the **feature analysis**: the values are equal to 0. \n",
    "\n",
    "The feature analysis process returns the importance of each feature training a model (in this case, a `DecisionTreeRegressor` because the target feature is continuous) that wants to predict the `Metrics.Review Score`. Since we need to fit a model, some pre-processing actions are carried out during Dataset Analysis. In particular, we need to impute missing values and also encode categorical features as `DecisionTreeRegresson` is going to throw errors otherwise. \n",
    "\n",
    "In the previous cells, encoding of the categorical features of this dataset has been deeply explained. However, what is important to understand is that we cannot use label encoding because it would lead to having non-sense splits, and one-hot encoding is the only alternative. In the case of genres and publishers, for the reasons explained above, we are able to reduce the overall number of new columns needed to encode them.  For `Title` column, instead, we are forced to drop it out since we would need 908 columns to encode very few information. If the values were all different, the feature would have been useless unless feature extraction would be performed on the strings. In this case, there are some repeated values that could be representative, but they are very few and they would probably not affect the predictions.\n",
    "\n",
    "The results of this process are printed using a dataframe to format data into a table which associates feature name with its importance. As we can see, the total number of columns have now become 63. The new dummy columns have `dtype=uint8` since the values can be 0 or 1 - the method `astype(bool)` could have been concatenated to the dummy columns generation rows in order to convert the type in Boolean for clarity.\n",
    "\n",
    "Moreover, we can observe that also other columns have importance equals to 0. We could easily drop out them all (and maybe also the ones with importance near to 0) in order to speed up a bit the model selection and evaluation phases, but feature selection was deliberately avoided because the overall time was pretty much the same.\n",
    "\n",
    "About **pre-processing** phase, we already did imputation and categorical features encoding. We still need to discretize the target feature into 7 classes and to address the class unbalancing since there is a huge difference between the number of instances with an `High` Review Score and that of those with `Extremely low` or `Extremely high`. I decided to use SMOTE (Synthetic Minority Oversampling Technique) instead of just duplicating instances hoping that this helps to train better models for minority classes. The new number of instances in 2842 because each class has 406 instances.\n",
    "\n",
    "The dataset is then split into two parts: the training set and the test set. About two-third for the former and one third for the second, which is the general proportion that allows the model to have sufficient data for training but leaving some data to perform the evaluation. The training set is going to be further split during cross-validation for **hyperparameters tuning**, automatically performed by the `GridSearchCV` and `RandomizedSearchCV` classes. More details about this phase can be found in the previous cells.\n",
    "\n",
    "The HP tuning is performed with four different algorithms: Decision Trees, Support Vector Machines, An ensemble methodology and MLPNs. The chosen ensemble algorithm is Random Forest, which combines different decision trees using the bagging method and selecting randomly the subset of features on which a decision tree can branch.\n",
    "\n",
    "The algorithms obviously have different hyperparameters, but they also have a different training time. In particular, MLPN is slower and it was necessary to reduce the combinations of parameters in order to have waitable execution times. That was not a problem because its behaviour seemed to underperform in comparison to the other ones, for which more combinations have been tested. In order to further reduce the time of tuning, I also reduced the number of folds in the cross-validation process and I distributed the workload between all the cores of the machine when necessary.\n",
    "\n",
    "In order to **select the best model** I compared the same scoring used to choose the best hyperparameters: accuracy. The best estimator in the `GridSearchCV` of Random Forests reaches an accuracy of more than 70%. This result is confirmed during the **evaluation** phase, in which the average accuracy is around the 75%. However, analysing the partial results for different classes, we can notice that the minor classes (the classes with a few instances) have very high precision and recall, next to 90%. Since they were synthetically oversampled and most of the instances are fake and probably over-represented, there is a big similarity that results in excellent results. As proof of this, the class with the worst results is `High` which had the biggest number of \"original\" instances. These observations have shown that results are not completely reliable since the oversampling affects too much predictions.\n",
    "\n",
    "In order to improve these results, we should first try to repeat all the process without addressing class unbalancing. This will definitely reduce the precision and recall of minor classes, because during the training phase we will have just 5 instances with an Extremely Low Metric Score and the remaining 3 will be used for evaluation. However, focusing on the major classes, we could understand if the big number of synthetic examples affected also the prediction of those classes who were not oversampled. If so, the overall results could be probably improved collecting new original data for the minor classes, if it is possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
